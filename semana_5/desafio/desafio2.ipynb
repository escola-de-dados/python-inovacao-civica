{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fd5ca6",
   "metadata": {},
   "source": [
    "# Desafio 2: Licitações publicadas hoje no Diário Oficial da União"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805e4af",
   "metadata": {},
   "source": [
    "Neste desafio você irá **acessar o Portal de Compras do Governo Federal (ComprasNET)** e raspar a **descrição** de todas as licitações que foram publicadas hoje no Diário Oficial da União.\n",
    "\n",
    "Antes de começar o desafio, [acesse o site](http://comprasnet.gov.br/ConsultaLicitacoes/ConsLicitacaoDia.asp) e se familiarize com ele. É esperado que tenha bastantes licitações sendo publicadas diariamente. É assim mesmo :)\n",
    "\n",
    "Este desafio é mais livre, assim você pode experimentar mais :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4bc5c3",
   "metadata": {},
   "source": [
    "## Importando as bibliotecas\n",
    "\n",
    "O fluxo de raspagem deve ser:\n",
    "\n",
    "1. Acessar a primeira página que apresenta as licitações de hoje\n",
    "2. Raspar a descrição de todas as licitações da página individualmente  \n",
    "   2.1. Raspe como se fosse um bloco de texto corrido mesmo  \n",
    "   2.2. Sem raspar nenhuma etiqueta HTML junto com o texto   \n",
    "3. Adicionar os itens da página em um `DataFrame` da `pandas` apenas com os campos `data` (dia de hoje) e `descricao` (descrição da licitação)\n",
    "4. Repetir os passos 1, 2 e 3 para cada página\n",
    "5. Salvar o `DataFrame` em JSON\n",
    "\n",
    "Realize aqui os `import` necessários para esta tarefa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95697f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1956ae9e",
   "metadata": {},
   "source": [
    "## Acessando a página inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887df39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95c6e3b0",
   "metadata": {},
   "source": [
    "## Extraindo os itens da página inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e21fe57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dce0708",
   "metadata": {},
   "source": [
    "## Adicionando ao DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd81a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b11124de",
   "metadata": {},
   "source": [
    "## Replicando para todas as páginas\n",
    "\n",
    "Recomenda-se transformar a extração de conteúdo da página em uma função que pode ser chamada para cada página."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "421f45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_licitacoes(response):\n",
    "    \"\"\"Se desejar, preencha esta função\"\"\"\n",
    "    return licitacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04acb264",
   "metadata": {},
   "source": [
    "E continuar o fluxo de extrações, página a página."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3703e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f65fbea3",
   "metadata": {},
   "source": [
    "## Salvando em JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a071701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
