{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fd5ca6",
   "metadata": {},
   "source": [
    "# Desafio 2: Licitações publicadas hoje no Diário Oficial da União"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805e4af",
   "metadata": {},
   "source": [
    "Neste desafio você irá **acessar o Portal de Compras do Governo Federal (ComprasNET)** e raspar a **descrição** de todas as licitações que foram publicadas hoje no Diário Oficial da União.\n",
    "\n",
    "Antes de começar o desafio, [acesse o site](http://comprasnet.gov.br/ConsultaLicitacoes/ConsLicitacaoDia.asp) e se familiarize com ele. É esperado que tenha bastantes licitações sendo publicadas diariamente. É assim mesmo :)\n",
    "\n",
    "Este desafio é mais livre, assim você pode experimentar mais :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4bc5c3",
   "metadata": {},
   "source": [
    "## Importando as bibliotecas\n",
    "\n",
    "O fluxo de raspagem deve ser:\n",
    "\n",
    "1. Acessar a primeira página que apresenta as licitações de hoje\n",
    "2. Raspar a descrição de todas as licitações da página individualmente  \n",
    "   2.1. Raspe como se fosse um bloco de texto corrido mesmo  \n",
    "   2.2. Sem raspar nenhuma etiqueta HTML junto com o texto   \n",
    "3. Adicionar os itens da página em um `DataFrame` da `pandas` apenas com os campos `data` (dia de hoje) e `descricao` (descrição da licitação)\n",
    "4. Repetir os passos 1, 2 e 3 para cada página\n",
    "5. Salvar o `DataFrame` em JSON\n",
    "\n",
    "Realize aqui os `import` necessários para esta tarefa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95697f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from requests_html import HTMLSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1956ae9e",
   "metadata": {},
   "source": [
    "## Acessando a página inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887df39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://comprasnet.gov.br/ConsultaLicitacoes/ConsLicitacaoDia.asp\"\n",
    "session = HTMLSession()\n",
    "response = session.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6e3b0",
   "metadata": {},
   "source": [
    "## Extraindo os itens da página inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e21fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "licitacoes = []\n",
    "rows = response.html.xpath(\"//form\")\n",
    "for row in rows:\n",
    "    descricao = row.xpath(\"./form/table/tr[2]//text()\")\n",
    "    descricao = '\\n'.join(descricao).strip()\n",
    "    item = {\n",
    "        \"data\": datetime.date.today(),\n",
    "        \"descricao\": descricao,\n",
    "    }\n",
    "    licitacoes.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce0708",
   "metadata": {},
   "source": [
    "## Adicionando ao DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd81a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_licitacoes = pd.DataFrame(licitacoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11124de",
   "metadata": {},
   "source": [
    "## Replicando para todas as páginas\n",
    "\n",
    "Recomenda-se transformar a extração de conteúdo da página em uma função que pode ser chamada para cada página."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "421f45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_licitacoes(response):\n",
    "    \"\"\"Se desejar, preencha esta função\"\"\"\n",
    "    licitacoes = []\n",
    "    rows = response.html.xpath(\"//form\")\n",
    "    for row in rows:\n",
    "        descricao = row.xpath(\"./form/table/tr[2]//text()\")\n",
    "        descricao = '\\n'.join(descricao).strip()\n",
    "        item = {\n",
    "            \"data\": datetime.date.today(),\n",
    "            \"descricao\": descricao,\n",
    "        }\n",
    "        licitacoes.append(item)\n",
    "    return licitacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04acb264",
   "metadata": {},
   "source": [
    "E continuar o fluxo de extrações, página a página."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3703e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "next_page_button = response.html.xpath(\"//input[@name='proxima']\")\n",
    "while next_page_button:\n",
    "    page += 1\n",
    "    next_page_url = f\"{url}?pagina={page}\"\n",
    "    response = session.get(next_page_url)\n",
    "    licitacoes = extract_licitacoes(response)\n",
    "    df_licitacoes = df_licitacoes.append(pd.DataFrame(licitacoes))\n",
    "    next_page_button = response.html.xpath(\"//input[@name='proxima']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65fbea3",
   "metadata": {},
   "source": [
    "## Salvando em JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a071701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_licitacoes.to_json('licitacoes.json', orient=\"records\", date_format=\"iso\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
